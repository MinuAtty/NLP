{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **NLP Analysis of Customer Support Chat Data**"
      ],
      "metadata": {
        "id": "FTjS7vx_xCWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import spacy  # For NLP tasks like tokenization, POS tagging\n",
        "import nltk  # For NLP tasks like stemming, tokenization"
      ],
      "metadata": {
        "id": "VJ03RNjz3seO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive  # For accessing files in Google Drive\n",
        "\n",
        "# Mount Google Drive to access files stored in it\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay0VY_rxLKUt",
        "outputId": "3332ef17-fa3a-4da5-86cf-b4f0464957db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J7vW-LXozLl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a42933f5-5035-4190-85b1-d9988901e30b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['customer_id      chat_date                   message_text \\n',\n",
              " '101              2024-01-10  09:00:00        \"I\\'m having trouble logging into my account, please help me.\" \\n',\n",
              " '102              2024-02-04  09:15:00        \"How do I change my password? I forgot the old one.\" \\n',\n",
              " '103              2024-04-10  09:30:00        \"Can I return a product that I bought last week? It\\'s defective.\" \\n',\n",
              " '104              2024-05-20  09:45:00        \"When will my order be shipped? I haven\\'t received any updates.\" \\n',\n",
              " '105              2024-06-08  10:00:00        \"I need to update my shipping address for my recent order.\" \\n',\n",
              " '106              2024-06-20  10:15:00        \"Is it possible to get a refund on a defective item I bought a month ago?\" \\n',\n",
              " '107              2024-07-15  10:30:00        \"My credit card was charged incorrectly. Can you assist with that?\" \\n',\n",
              " '108              2024-08-18  10:45:00        \"I was charged twice for the same order. Please check it.\" \\n',\n",
              " '109              2024-10-05  11:00:00        \"Do you have any new deals or discounts for the upcoming holiday season?\" \\n',\n",
              " '110              2024-11-10  11:15:00        \"Can you explain the warranty policy on your electronics products?\"']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Read the contents of the file 'Chat Log Dataset.txt' into a list of lines\n",
        "with open(\"/content/drive/MyDrive/Chat Log Dataset.txt\") as f:\n",
        "    text = f.readlines()\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join the list of lines into a single string, separating each line with a space\n",
        "text = \" \".join(text)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "HZ7MUsSf2GRB",
        "outputId": "edbe2199-ffec-4820-be52-f54df7115f38"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'customer_id      chat_date                   message_text \\n 101              2024-01-10  09:00:00        \"I\\'m having trouble logging into my account, please help me.\" \\n 102              2024-02-04  09:15:00        \"How do I change my password? I forgot the old one.\" \\n 103              2024-04-10  09:30:00        \"Can I return a product that I bought last week? It\\'s defective.\" \\n 104              2024-05-20  09:45:00        \"When will my order be shipped? I haven\\'t received any updates.\" \\n 105              2024-06-08  10:00:00        \"I need to update my shipping address for my recent order.\" \\n 106              2024-06-20  10:15:00        \"Is it possible to get a refund on a defective item I bought a month ago?\" \\n 107              2024-07-15  10:30:00        \"My credit card was charged incorrectly. Can you assist with that?\" \\n 108              2024-08-18  10:45:00        \"I was charged twice for the same order. Please check it.\" \\n 109              2024-10-05  11:00:00        \"Do you have any new deals or discounts for the upcoming holiday season?\" \\n 110              2024-11-10  11:15:00        \"Can you explain the warranty policy on your electronics products?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Preprocessing"
      ],
      "metadata": {
        "id": "RQ_v3lmubTrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization"
      ],
      "metadata": {
        "id": "DTlu6CWiBJgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "import re  # For regular expressions\n",
        "\n",
        "# Define a regex pattern to match timestamps and capture the message after the timestamp\n",
        "pattern = re.compile(r\"\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2}:\\d{2}\\s+(.*)\")\n",
        "\n",
        "# Extract the messages from the text using the regex pattern\n",
        "message_texts = pattern.findall(text)\n",
        "\n",
        "# Load a blank SpaCy NLP model for English and add the sentencizer component\n",
        "nlp = spacy.blank(\"en\")\n",
        "nlp.add_pipe(\"sentencizer\")  # Add the sentencizer to detect sentence boundaries\n",
        "\n",
        "# Loop through each extracted message, split into sentences, and then tokenize\n",
        "for message_text in message_texts:\n",
        "    doc = nlp(message_text)  # Process the message with SpaCy\n",
        "    sentences = [sent.text for sent in doc.sents]  # Extract sentences from the message\n",
        "\n",
        "    print(\"Extracted message:\", message_text)\n",
        "    print(\"Sentences:\", sentences)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sent_doc = nlp(sentence)  # Process each sentence separately\n",
        "        tokens = [token.text for token in sent_doc]  # Extract tokens (words) from the sentence\n",
        "        print(\"Sentence:\", sentence)\n",
        "        print(\"Tokens:\", tokens)\n",
        "        print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4UkBFzF8wV_",
        "outputId": "b8b8be12-9edb-4abb-960d-27f533d3b09c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted message: \"I'm having trouble logging into my account, please help me.\" \n",
            "Sentences: ['\"I\\'m having trouble logging into my account, please help me.\"']\n",
            "Sentence: \"I'm having trouble logging into my account, please help me.\"\n",
            "Tokens: ['\"', 'I', \"'m\", 'having', 'trouble', 'logging', 'into', 'my', 'account', ',', 'please', 'help', 'me', '.', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Extracted message: \"How do I change my password? I forgot the old one.\" \n",
            "Sentences: ['\"How do I change my password?', 'I forgot the old one.\"']\n",
            "Sentence: \"How do I change my password?\n",
            "Tokens: ['\"', 'How', 'do', 'I', 'change', 'my', 'password', '?']\n",
            "--------------------------------------------------------------------------------\n",
            "Sentence: I forgot the old one.\"\n",
            "Tokens: ['I', 'forgot', 'the', 'old', 'one', '.', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Extracted message: \"Can I return a product that I bought last week? It's defective.\" \n",
            "Sentences: ['\"Can I return a product that I bought last week?', 'It\\'s defective.\"']\n",
            "Sentence: \"Can I return a product that I bought last week?\n",
            "Tokens: ['\"', 'Can', 'I', 'return', 'a', 'product', 'that', 'I', 'bought', 'last', 'week', '?']\n",
            "--------------------------------------------------------------------------------\n",
            "Sentence: It's defective.\"\n",
            "Tokens: ['It', \"'s\", 'defective', '.', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Extracted message: \"When will my order be shipped? I haven't received any updates.\" \n",
            "Sentences: ['\"When will my order be shipped?', 'I haven\\'t received any updates.\"']\n",
            "Sentence: \"When will my order be shipped?\n",
            "Tokens: ['\"', 'When', 'will', 'my', 'order', 'be', 'shipped', '?']\n",
            "--------------------------------------------------------------------------------\n",
            "Sentence: I haven't received any updates.\"\n",
            "Tokens: ['I', 'have', \"n't\", 'received', 'any', 'updates', '.', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Extracted message: \"I need to update my shipping address for my recent order.\" \n",
            "Sentences: ['\"I need to update my shipping address for my recent order.\"']\n",
            "Sentence: \"I need to update my shipping address for my recent order.\"\n",
            "Tokens: ['\"', 'I', 'need', 'to', 'update', 'my', 'shipping', 'address', 'for', 'my', 'recent', 'order', '.', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Extracted message: \"Is it possible to get a refund on a defective item I bought a month ago?\" \n",
            "Sentences: ['\"Is it possible to get a refund on a defective item I bought a month ago?\"']\n",
            "Sentence: \"Is it possible to get a refund on a defective item I bought a month ago?\"\n",
            "Tokens: ['\"', 'Is', 'it', 'possible', 'to', 'get', 'a', 'refund', 'on', 'a', 'defective', 'item', 'I', 'bought', 'a', 'month', 'ago', '?', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Extracted message: \"My credit card was charged incorrectly. Can you assist with that?\" \n",
            "Sentences: ['\"My credit card was charged incorrectly.', 'Can you assist with that?\"']\n",
            "Sentence: \"My credit card was charged incorrectly.\n",
            "Tokens: ['\"', 'My', 'credit', 'card', 'was', 'charged', 'incorrectly', '.']\n",
            "--------------------------------------------------------------------------------\n",
            "Sentence: Can you assist with that?\"\n",
            "Tokens: ['Can', 'you', 'assist', 'with', 'that', '?', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Extracted message: \"I was charged twice for the same order. Please check it.\" \n",
            "Sentences: ['\"I was charged twice for the same order.', 'Please check it.\"']\n",
            "Sentence: \"I was charged twice for the same order.\n",
            "Tokens: ['\"', 'I', 'was', 'charged', 'twice', 'for', 'the', 'same', 'order', '.']\n",
            "--------------------------------------------------------------------------------\n",
            "Sentence: Please check it.\"\n",
            "Tokens: ['Please', 'check', 'it', '.', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Extracted message: \"Do you have any new deals or discounts for the upcoming holiday season?\" \n",
            "Sentences: ['\"Do you have any new deals or discounts for the upcoming holiday season?\"']\n",
            "Sentence: \"Do you have any new deals or discounts for the upcoming holiday season?\"\n",
            "Tokens: ['\"', 'Do', 'you', 'have', 'any', 'new', 'deals', 'or', 'discounts', 'for', 'the', 'upcoming', 'holiday', 'season', '?', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Extracted message: \"Can you explain the warranty policy on your electronics products?\"\n",
            "Sentences: ['\"Can you explain the warranty policy on your electronics products?\"']\n",
            "Sentence: \"Can you explain the warranty policy on your electronics products?\"\n",
            "Tokens: ['\"', 'Can', 'you', 'explain', 'the', 'warranty', 'policy', 'on', 'your', 'electronics', 'products', '?', '\"']\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stemming and Lemmatization"
      ],
      "metadata": {
        "id": "Jj7TX8skBQxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PorterStemmer from NLTK for stemming (reducing words to their root form)\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Create an instance of the PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Load the SpaCy English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Loop through each message to perform stemming and lemmatization\n",
        "for message_text in message_texts:\n",
        "    doc = nlp(message_text)  # Process the message with SpaCy\n",
        "    tokens = [token.text for token in doc]  # Extract tokens from the message\n",
        "\n",
        "    # Apply stemming to each token using the PorterStemmer\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    # Apply lemmatization to each token using SpaCy (returns base form of the word)\n",
        "    lemmatized_tokens = [token.lemma_ for token in doc]\n",
        "\n",
        "    print(f\"Original Message: {message_text}\")\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "    print(f\"Stemmed Tokens: {stemmed_tokens}\")\n",
        "    print(f\"Lemmatized Tokens: {lemmatized_tokens}\")\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "UFHbm939LFBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a0d37e-abf1-4def-f796-ec3294f16291"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Message: \"I'm having trouble logging into my account, please help me.\" \n",
            "Tokens: ['\"', 'I', \"'m\", 'having', 'trouble', 'logging', 'into', 'my', 'account', ',', 'please', 'help', 'me', '.', '\"']\n",
            "Stemmed Tokens: ['\"', 'i', \"'m\", 'have', 'troubl', 'log', 'into', 'my', 'account', ',', 'pleas', 'help', 'me', '.', '\"']\n",
            "Lemmatized Tokens: ['\"', 'I', 'be', 'have', 'trouble', 'log', 'into', 'my', 'account', ',', 'please', 'help', 'I', '.', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Original Message: \"How do I change my password? I forgot the old one.\" \n",
            "Tokens: ['\"', 'How', 'do', 'I', 'change', 'my', 'password', '?', 'I', 'forgot', 'the', 'old', 'one', '.', '\"']\n",
            "Stemmed Tokens: ['\"', 'how', 'do', 'i', 'chang', 'my', 'password', '?', 'i', 'forgot', 'the', 'old', 'one', '.', '\"']\n",
            "Lemmatized Tokens: ['\"', 'how', 'do', 'I', 'change', 'my', 'password', '?', 'I', 'forget', 'the', 'old', 'one', '.', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Original Message: \"Can I return a product that I bought last week? It's defective.\" \n",
            "Tokens: ['\"', 'Can', 'I', 'return', 'a', 'product', 'that', 'I', 'bought', 'last', 'week', '?', 'It', \"'s\", 'defective', '.', '\"']\n",
            "Stemmed Tokens: ['\"', 'can', 'i', 'return', 'a', 'product', 'that', 'i', 'bought', 'last', 'week', '?', 'it', \"'s\", 'defect', '.', '\"']\n",
            "Lemmatized Tokens: ['\"', 'can', 'I', 'return', 'a', 'product', 'that', 'I', 'buy', 'last', 'week', '?', 'it', 'be', 'defective', '.', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Original Message: \"When will my order be shipped? I haven't received any updates.\" \n",
            "Tokens: ['\"', 'When', 'will', 'my', 'order', 'be', 'shipped', '?', 'I', 'have', \"n't\", 'received', 'any', 'updates', '.', '\"']\n",
            "Stemmed Tokens: ['\"', 'when', 'will', 'my', 'order', 'be', 'ship', '?', 'i', 'have', \"n't\", 'receiv', 'ani', 'updat', '.', '\"']\n",
            "Lemmatized Tokens: ['\"', 'when', 'will', 'my', 'order', 'be', 'ship', '?', 'I', 'have', 'not', 'receive', 'any', 'update', '.', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Original Message: \"I need to update my shipping address for my recent order.\" \n",
            "Tokens: ['\"', 'I', 'need', 'to', 'update', 'my', 'shipping', 'address', 'for', 'my', 'recent', 'order', '.', '\"']\n",
            "Stemmed Tokens: ['\"', 'i', 'need', 'to', 'updat', 'my', 'ship', 'address', 'for', 'my', 'recent', 'order', '.', '\"']\n",
            "Lemmatized Tokens: ['\"', 'I', 'need', 'to', 'update', 'my', 'shipping', 'address', 'for', 'my', 'recent', 'order', '.', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Original Message: \"Is it possible to get a refund on a defective item I bought a month ago?\" \n",
            "Tokens: ['\"', 'Is', 'it', 'possible', 'to', 'get', 'a', 'refund', 'on', 'a', 'defective', 'item', 'I', 'bought', 'a', 'month', 'ago', '?', '\"']\n",
            "Stemmed Tokens: ['\"', 'is', 'it', 'possibl', 'to', 'get', 'a', 'refund', 'on', 'a', 'defect', 'item', 'i', 'bought', 'a', 'month', 'ago', '?', '\"']\n",
            "Lemmatized Tokens: ['\"', 'be', 'it', 'possible', 'to', 'get', 'a', 'refund', 'on', 'a', 'defective', 'item', 'I', 'buy', 'a', 'month', 'ago', '?', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Original Message: \"My credit card was charged incorrectly. Can you assist with that?\" \n",
            "Tokens: ['\"', 'My', 'credit', 'card', 'was', 'charged', 'incorrectly', '.', 'Can', 'you', 'assist', 'with', 'that', '?', '\"']\n",
            "Stemmed Tokens: ['\"', 'my', 'credit', 'card', 'wa', 'charg', 'incorrectli', '.', 'can', 'you', 'assist', 'with', 'that', '?', '\"']\n",
            "Lemmatized Tokens: ['\"', 'my', 'credit', 'card', 'be', 'charge', 'incorrectly', '.', 'can', 'you', 'assist', 'with', 'that', '?', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Original Message: \"I was charged twice for the same order. Please check it.\" \n",
            "Tokens: ['\"', 'I', 'was', 'charged', 'twice', 'for', 'the', 'same', 'order', '.', 'Please', 'check', 'it', '.', '\"']\n",
            "Stemmed Tokens: ['\"', 'i', 'wa', 'charg', 'twice', 'for', 'the', 'same', 'order', '.', 'pleas', 'check', 'it', '.', '\"']\n",
            "Lemmatized Tokens: ['\"', 'I', 'be', 'charge', 'twice', 'for', 'the', 'same', 'order', '.', 'please', 'check', 'it', '.', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Original Message: \"Do you have any new deals or discounts for the upcoming holiday season?\" \n",
            "Tokens: ['\"', 'Do', 'you', 'have', 'any', 'new', 'deals', 'or', 'discounts', 'for', 'the', 'upcoming', 'holiday', 'season', '?', '\"']\n",
            "Stemmed Tokens: ['\"', 'do', 'you', 'have', 'ani', 'new', 'deal', 'or', 'discount', 'for', 'the', 'upcom', 'holiday', 'season', '?', '\"']\n",
            "Lemmatized Tokens: ['\"', 'do', 'you', 'have', 'any', 'new', 'deal', 'or', 'discount', 'for', 'the', 'upcoming', 'holiday', 'season', '?', '\"']\n",
            "--------------------------------------------------------------------------------\n",
            "Original Message: \"Can you explain the warranty policy on your electronics products?\"\n",
            "Tokens: ['\"', 'Can', 'you', 'explain', 'the', 'warranty', 'policy', 'on', 'your', 'electronics', 'products', '?', '\"']\n",
            "Stemmed Tokens: ['\"', 'can', 'you', 'explain', 'the', 'warranti', 'polici', 'on', 'your', 'electron', 'product', '?', '\"']\n",
            "Lemmatized Tokens: ['\"', 'can', 'you', 'explain', 'the', 'warranty', 'policy', 'on', 'your', 'electronic', 'product', '?', '\"']\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. POS Tagging"
      ],
      "metadata": {
        "id": "6Xn1xndafHqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare to store POS tags (part-of-speech tags) for each message\n",
        "results = []\n",
        "\n",
        "# Loop through each message and extract its POS tags\n",
        "for message_text in message_texts:\n",
        "    doc = nlp(message_text)  # Process the message with SpaCy\n",
        "    # Extract tokens and their POS tags, formatting them with \" | \"\n",
        "    pos_tags = [f\"{token.text} | {token.pos_}\" for token in doc]\n",
        "    results.append({\"message_text\": message_text, \"pos_tags\": pos_tags})  # Store the results\n",
        "\n",
        "# Print the POS tags for each message\n",
        "for result in results:\n",
        "    print(f\"Message: {result['message_text']}\")\n",
        "    print(f\"POS Tags: {', '.join(result['pos_tags'])}\")  # Join tags with a comma for readability\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW_un6Crlbd7",
        "outputId": "1dec35ab-86d2-440b-cb3d-ff0d4f4209fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message: \"I'm having trouble logging into my account, please help me.\" \n",
            "POS Tags: \" | PUNCT, I | PRON, 'm | AUX, having | VERB, trouble | NOUN, logging | VERB, into | ADP, my | PRON, account | NOUN, , | PUNCT, please | INTJ, help | VERB, me | PRON, . | PUNCT, \" | PUNCT\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"How do I change my password? I forgot the old one.\" \n",
            "POS Tags: \" | PUNCT, How | SCONJ, do | AUX, I | PRON, change | VERB, my | PRON, password | NOUN, ? | PUNCT, I | PRON, forgot | VERB, the | DET, old | ADJ, one | NUM, . | PUNCT, \" | PUNCT\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"Can I return a product that I bought last week? It's defective.\" \n",
            "POS Tags: \" | PUNCT, Can | AUX, I | PRON, return | VERB, a | DET, product | NOUN, that | PRON, I | PRON, bought | VERB, last | ADJ, week | NOUN, ? | PUNCT, It | PRON, 's | AUX, defective | ADJ, . | PUNCT, \" | PUNCT\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"When will my order be shipped? I haven't received any updates.\" \n",
            "POS Tags: \" | PUNCT, When | SCONJ, will | AUX, my | PRON, order | NOUN, be | AUX, shipped | VERB, ? | PUNCT, I | PRON, have | AUX, n't | PART, received | VERB, any | DET, updates | NOUN, . | PUNCT, \" | PUNCT\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"I need to update my shipping address for my recent order.\" \n",
            "POS Tags: \" | PUNCT, I | PRON, need | VERB, to | PART, update | VERB, my | PRON, shipping | NOUN, address | NOUN, for | ADP, my | PRON, recent | ADJ, order | NOUN, . | PUNCT, \" | PUNCT\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"Is it possible to get a refund on a defective item I bought a month ago?\" \n",
            "POS Tags: \" | PUNCT, Is | AUX, it | PRON, possible | ADJ, to | PART, get | VERB, a | DET, refund | NOUN, on | ADP, a | DET, defective | ADJ, item | NOUN, I | PRON, bought | VERB, a | DET, month | NOUN, ago | ADV, ? | PUNCT, \" | PUNCT\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"My credit card was charged incorrectly. Can you assist with that?\" \n",
            "POS Tags: \" | PUNCT, My | PRON, credit | NOUN, card | NOUN, was | AUX, charged | VERB, incorrectly | ADV, . | PUNCT, Can | AUX, you | PRON, assist | VERB, with | ADP, that | PRON, ? | PUNCT, \" | PUNCT\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"I was charged twice for the same order. Please check it.\" \n",
            "POS Tags: \" | PUNCT, I | PRON, was | AUX, charged | VERB, twice | ADV, for | ADP, the | DET, same | ADJ, order | NOUN, . | PUNCT, Please | INTJ, check | VERB, it | PRON, . | PUNCT, \" | PUNCT\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"Do you have any new deals or discounts for the upcoming holiday season?\" \n",
            "POS Tags: \" | PUNCT, Do | AUX, you | PRON, have | VERB, any | DET, new | ADJ, deals | NOUN, or | CCONJ, discounts | NOUN, for | ADP, the | DET, upcoming | ADJ, holiday | NOUN, season | NOUN, ? | PUNCT, \" | PUNCT\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"Can you explain the warranty policy on your electronics products?\"\n",
            "POS Tags: \" | PUNCT, Can | AUX, you | PRON, explain | VERB, the | DET, warranty | NOUN, policy | NOUN, on | ADP, your | PRON, electronics | NOUN, products | NOUN, ? | PUNCT, \" | PUNCT\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SpaCy returns a list of the names of all the pipeline components currently loaded in the nlp object\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cnMFeaKx1WD",
        "outputId": "323e50a2-e5db-4362-bdcc-6f2259545635"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tok2vec:**\n",
        "\n",
        "- A transformer-like layer that converts tokens into vector representations.\n",
        "- It is typically used as a base layer to share word embeddings across other components.\n",
        "- Useful for improving downstream tasks like tagging, parsing, and NER by providing context-aware word embeddings.\n",
        "\n",
        "**tagger:**\n",
        "\n",
        "- The part-of-speech (POS) tagger.\n",
        "- Assigns grammatical tags (e.g., noun, verb) to each token in the text.\n",
        "- Example: In \"She runs fast,\" the tagger assigns \"PRON\" to \"She,\" \"VERB\" to \"runs,\" and \"ADV\" to \"fast.\"\n",
        "\n",
        "**parser:**\n",
        "\n",
        "- The dependency parser.\n",
        "- Identifies syntactic relationships between words in a sentence (e.g., subject-verb-object structure).\n",
        "- Example: In \"The dog chased the cat,\" the parser determines that \"dog\" is the subject and \"cat\" is the object of the verb \"chased.\"\n",
        "\n",
        "**attribute_ruler:**\n",
        "\n",
        "- A component that modifies token attributes (e.g., lemma, POS) based on custom rules or patterns.\n",
        "- Useful for tasks like normalizing text (e.g., standardizing abbreviations, handling exceptions).\n",
        "\n",
        "**lemmatizer:**\n",
        "\n",
        "- Generates the base form (lemma) of each word.\n",
        "- Example: The word \"running\" is lemmatized to \"run,\" and \"better\" is lemmatized to \"good.\"\n",
        "\n",
        "**ner:**\n",
        "\n",
        "- The named entity recognizer.\n",
        "- Identifies and labels named entities in the text, such as dates, names, locations, organizations, etc.\n",
        "- Example: In \"John works at Google in California,\" the ner component labels \"John\" as PERSON, \"Google\" as ORG, and \"California\" as GPE (Geopolitical Entity)."
      ],
      "metadata": {
        "id": "iuAqT0W0baQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Named Entity Recognition (NER)"
      ],
      "metadata": {
        "id": "IBeD2BWEjj9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each message to extract named entities using SpaCy's NER (Named Entity Recognition)\n",
        "for message_text in message_texts:\n",
        "    doc = nlp(message_text)  # Process the message with SpaCy\n",
        "\n",
        "    print(f\"Message: {message_text}\")\n",
        "    print(\"Entities:\")\n",
        "\n",
        "    # Loop through each entity recognized in the message and print its text, label, and description\n",
        "    for ent in doc.ents:\n",
        "        print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))\n",
        "\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8hWf8vzjmiV",
        "outputId": "09e260bc-c15e-48ca-d38c-5cb83b9eb5f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message: \"I'm having trouble logging into my account, please help me.\" \n",
            "Entities:\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"How do I change my password? I forgot the old one.\" \n",
            "Entities:\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"Can I return a product that I bought last week? It's defective.\" \n",
            "Entities:\n",
            "last week  |  DATE  |  Absolute or relative dates or periods\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"When will my order be shipped? I haven't received any updates.\" \n",
            "Entities:\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"I need to update my shipping address for my recent order.\" \n",
            "Entities:\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"Is it possible to get a refund on a defective item I bought a month ago?\" \n",
            "Entities:\n",
            "a month ago  |  DATE  |  Absolute or relative dates or periods\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"My credit card was charged incorrectly. Can you assist with that?\" \n",
            "Entities:\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"I was charged twice for the same order. Please check it.\" \n",
            "Entities:\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"Do you have any new deals or discounts for the upcoming holiday season?\" \n",
            "Entities:\n",
            "the upcoming holiday season  |  DATE  |  Absolute or relative dates or periods\n",
            "--------------------------------------------------------------------------------\n",
            "Message: \"Can you explain the warranty policy on your electronics products?\"\n",
            "Entities:\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import SpaCy's displacy module for visualizing entities\n",
        "from spacy import displacy\n",
        "\n",
        "# Select a few messages (at indices 2, 5, and 8) to visualize named entities\n",
        "docs = [nlp(message_texts[i]) for i in [2, 5, 8]]\n",
        "\n",
        "# Render the entities in these selected messages using displacy\n",
        "displacy.render(docs, style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "a28fadpuwOBN",
        "outputId": "a649dd59-14b3-4fc6-9916-adf84b82e4c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">&quot;Can I return a product that I bought \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    last week\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "? It's defective.&quot; </div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">&quot;Is it possible to get a refund on a defective item I bought \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    a month ago\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "?&quot; </div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">&quot;Do you have any new deals or discounts for \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the upcoming holiday season\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "?&quot; </div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Analysis & Insights"
      ],
      "metadata": {
        "id": "Ldayd4tGBCpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common Issues"
      ],
      "metadata": {
        "id": "H2Z_RBiQDB23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Initialize a Counter object to count complaint-related terms\n",
        "complaints = Counter()\n",
        "\n",
        "# Process each message\n",
        "for message_text in message_texts:\n",
        "    # Tokenize the message (assuming `nlp` is a spaCy pipeline object)\n",
        "    doc = nlp(message_text)\n",
        "    for token in doc:\n",
        "        if token.is_alpha and not token.is_stop:  # Consider only alphabetical tokens and exclude stop words\n",
        "            complaints.update([token.lemma_])  # Update the complaint counter with the lemmatized token\n",
        "\n",
        "print(\"Common complaint terms:\", complaints.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOqHuzGusZ9n",
        "outputId": "3bbfc79c-f6d2-4afa-a693-a85eec60d748"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common complaint terms: [('order', 3), ('product', 2), ('buy', 2), ('defective', 2), ('update', 2), ('charge', 2), ('have', 1), ('trouble', 1), ('log', 1), ('account', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Topic Discovery"
      ],
      "metadata": {
        "id": "e_SKZhb2TOO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TfidfVectorizer from scikit-learn for TF-IDF vectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd  # For handling data in DataFrames\n",
        "\n",
        "# Initialize TfidfVectorizer to compute TF-IDF values, excluding English stop words\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Fit the vectorizer to the message texts and transform the texts into a TF-IDF matrix\n",
        "X = vectorizer.fit_transform(message_texts)\n",
        "\n",
        "# Convert the TF-IDF matrix into a DataFrame for easier analysis\n",
        "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# For each message, find the top 5 words with the highest TF-IDF scores\n",
        "top_words_per_message = df.apply(lambda x: pd.Series(x.nlargest(5).index), axis=1)\n",
        "\n",
        "print(top_words_per_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfsOtlplKA5v",
        "outputId": "b62567ba-6db5-4634-d623-ed742c4591f0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             0          1        2            3          4\n",
            "0      account     having     help      logging    trouble\n",
            "1       change     forgot      old     password    account\n",
            "2      product     return     week       bought  defective\n",
            "3        haven   received  shipped      updates      order\n",
            "4      address       need   recent     shipping     update\n",
            "5          ago       item    month     possible     refund\n",
            "6       assist       card   credit  incorrectly    charged\n",
            "7        check      twice  charged        order    account\n",
            "8        deals  discounts  holiday          new     season\n",
            "9  electronics    explain   policy     products   warranty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment Insight"
      ],
      "metadata": {
        "id": "XbtoLDHOTSsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of positive and negative words (for sentiment analysis)\n",
        "positive_words = {\"help\", \"update\", \"possible\", \"assist\", \"new\", \"discounts\", \"explain\", \"warranty\"}\n",
        "negative_words = {\"trouble\", \"forgot\", \"defective\", \"haven't\", \"refund\", \"charged\", \"incorrectly\", \"twice\", \"return\"}\n",
        "\n",
        "# Define a function to classify the sentiment of a message based on predefined positive and negative words\n",
        "def classify_sentiment(message):\n",
        "    # Tokenize the message and lemmatize each token\n",
        "    tokens = [token.lemma_ for token in nlp(message)]\n",
        "\n",
        "    # Count occurrences of positive and negative words in the message\n",
        "    pos_count = sum(1 for token in tokens if token in positive_words)\n",
        "    neg_count = sum(1 for token in tokens if token in negative_words)\n",
        "\n",
        "    # Classify the message as 'Positive', 'Negative', or 'Neutral' based on the counts\n",
        "    if pos_count > neg_count:\n",
        "        return 'Positive'\n",
        "    elif neg_count > pos_count:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Classify the sentiment of each message and count occurrences of each sentiment\n",
        "sentiment_counts = {\"Positive\": 0, \"Negative\": 0, \"Neutral\": 0}\n",
        "sentiments = []\n",
        "\n",
        "for message in message_texts:\n",
        "    sentiment = classify_sentiment(message)\n",
        "    sentiments.append(sentiment)\n",
        "    sentiment_counts[sentiment] += 1\n",
        "\n",
        "# Print the sentiments for each message\n",
        "print(\"Sentiments for each message:\")\n",
        "for message, sentiment in zip(message_texts, sentiments):\n",
        "    print(f\"Message: {message[:50]}... Sentiment: {sentiment}\")\n",
        "\n",
        "# Print the counts of each sentiment\n",
        "print(\"\\nSentiment counts:\")\n",
        "for sentiment, count in sentiment_counts.items():\n",
        "    print(f\"{sentiment}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPfkuJKYwh3T",
        "outputId": "12fdeee3-9eb8-4fb3-9eed-0d8e81dc42b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiments for each message:\n",
            "Message: \"I'm having trouble logging into my account, pleas... Sentiment: Neutral\n",
            "Message: \"How do I change my password? I forgot the old one... Sentiment: Neutral\n",
            "Message: \"Can I return a product that I bought last week? I... Sentiment: Negative\n",
            "Message: \"When will my order be shipped? I haven't received... Sentiment: Positive\n",
            "Message: \"I need to update my shipping address for my recen... Sentiment: Positive\n",
            "Message: \"Is it possible to get a refund on a defective ite... Sentiment: Negative\n",
            "Message: \"My credit card was charged incorrectly. Can you a... Sentiment: Neutral\n",
            "Message: \"I was charged twice for the same order. Please ch... Sentiment: Negative\n",
            "Message: \"Do you have any new deals or discounts for the up... Sentiment: Positive\n",
            "Message: \"Can you explain the warranty policy on your elect... Sentiment: Positive\n",
            "\n",
            "Sentiment counts:\n",
            "Positive: 4\n",
            "Negative: 3\n",
            "Neutral: 3\n"
          ]
        }
      ]
    }
  ]
}